{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import necessary libraries\n",
        "import gradio as gr\n",
        "import openai\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TextStreamer,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "from IPython.display import Markdown, display, update_display"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Constants\n",
        "AUDIO_MODEL = \"whisper-1\"\n",
        "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "# %% [markdown]\n",
        "# ### Mount Google Drive\n",
        "# This section mounts Google Drive to access audio files directly."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the audio file\n",
        "audio_filename = \"/content/drive/MyDrive/llms/denver_extract.mp3\"\n",
        "\n",
        "# %% [markdown]\n",
        "# ### Define Gradio Interface\n",
        "# The function below loads the audio file, sends it to OpenAI Whisper for transcription, and generates meeting minutes using the LLaMA model.\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define Gradio interface function\n",
        "def generate_minutes(audio):\n",
        "    # OpenAI Whisper transcription\n",
        "    with open(audio, \"rb\") as audio_file:\n",
        "        transcription = openai.Audio.transcribe(\n",
        "            model=AUDIO_MODEL, file=audio_file, response_format=\"text\"\n",
        "        )\n",
        "\n",
        "    # Prepare for GPT-4 or similar model\n",
        "    system_message = \"Produce minutes of meetings in markdown with summary, discussion points, takeaways, and action items.\"\n",
        "    user_prompt = f\"Here is a transcript from a council meeting:\\n{transcription}\"\n",
        "\n",
        "    prompts = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    # %% [markdown]\n",
        "    # #### Stream back results in markdown\n",
        "\n",
        "    stream = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\", messages=prompts, temperature=0.7, stream=True\n",
        "    )\n",
        "\n",
        "    reply = \"\"\n",
        "    display_handle = display(Markdown(\"\"), display_id=True)\n",
        "    for chunk in stream:\n",
        "        reply += chunk.choices[0].delta.content or \"\"\n",
        "        reply = reply.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
        "        update_display(Markdown(reply), display_id=display_handle.display_id)\n",
        "\n",
        "    return reply\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup Gradio UI\n",
        "gr.Interface(\n",
        "    fn=generate_minutes,\n",
        "    inputs=\"audio\",\n",
        "    outputs=\"markdown\",\n",
        "    title=\"Meeting Minutes Generator\",\n",
        "    description=\"Upload an audio file to generate meeting minutes.\",\n",
        ").launch(share=True)\n",
        "\n",
        "# %% [markdown]\n",
        "# ### Optional: Saving as Markdown\n",
        "# The output can be saved as a Markdown file or downloaded after processing.\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}